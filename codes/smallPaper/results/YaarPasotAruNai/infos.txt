train_batch_size = 32
train_number_epochs = 30
lr= 0.00005

Weight ini: mean 0, std 0.01
Batch norm with L2=2e-4
Ip normalize= 0.05,0.05
 
0 for similar image and 1 for dis similar
scratch
Contrastive Loss function...........margin= 
80% 20% train valid data
resize to 120X120X3
 
For early stopping:
Train Accuracy: 55.17 %
Test Accuracy: 55.55 %
 
For fully trained:
Train Accuracy: 63.01 %
Test Accuracy: 57.5 %



class SiameseNetwork(nn.Module):  
                                                                                                  #ip size: 120 X 120 X 3
  def __init__(self):

    super(SiameseNetwork, self).__init__()

    self.Conv1_1=  nn.Sequential(
        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(32),
        nn.ReLU(inplace=True)
    )
    self.Conv1_2=  nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(32),
        nn.ReLU(inplace=True)
    )
    self.Pooling1_1= nn.MaxPool2d(kernel_size=2, stride=2, padding=0)

    self.Conv2_1=  nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(inplace=True)
    )
    self.Conv2_2=  nn.Sequential(
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(inplace=True)
    )
    self.Pooling2_1= nn.MaxPool2d(kernel_size=2, stride=2, padding=0)

    self.Conv3_1=  nn.Sequential(
        nn.Conv2d(in_channels=128, out_channels=512, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(512),
        nn.ReLU(inplace=True)
    )
    self.Conv3_2=  nn.Sequential(
        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(512),
        nn.ReLU(inplace=True)
    )
    self.Pooling3_1= nn.MaxPool2d(kernel_size=2, stride=2, padding=0)

    self.Conv4=  nn.Sequential(
        nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(1024),
        nn.ReLU(inplace=True)
    )

    self.FC = nn.Sequential(
        nn.Linear(15*15*1024, 400),
        nn.BatchNorm1d(400),                ##remove if required
        nn.Linear(400, 400),
        nn.BatchNorm1d(400),                ##remove if required
        nn.Linear(400, 400)
    )
    self.initialize_weights()


  def initialize_weights(self):                           ##########################################33
    cnt=0
    for m in self.modules():
      
      if isinstance(m,nn.Conv2d):
        cnt+=1
        nn.init.normal_(m.weight, mean=0.0, std=0.01)    ##########################################33
        if cnt==1:
          # bias zero
          if m.bias is not None:
            nn.init.constant_(m.bias,0)
        else:
          nn.init.normal_(m.bias, mean=0.5, std=0.01)
      
      if isinstance(m,nn.Linear):
        nn.init.normal_(m.weight, mean=0.0, std=0.01)     ##########################################33


  def forward_simplifier(self,x):
    x= self.Conv1_1(x)
    x= self.Conv1_2(x)
    x= self.Pooling1_1(x)

    x= self.Conv2_1(x)
    x= self.Conv2_2(x)
    x= self.Pooling2_1(x)

    x= self.Conv3_1(x)
    x= self.Conv3_2(x)
    x= self.Pooling3_1(x)

    x= self.Conv4(x)

    x= x.view(-1,15*15*1024)

    x= self.FC(x)

    return x

  def forward(self, input1, input2):                                                  # op dim= 400
    output1= self.forward_simplifier(input1)
    output2= self.forward_simplifier(input2)
    
    return output1, output2

