{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mkaing_the_splits_good.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RtrwSwXAaiN",
        "outputId": "1bb8990d-4e83-4a88-b019-2a21cd5d8704"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SD0yoKpAgAH"
      },
      "source": [
        "path_to_train_set='./gdrive/MyDrive/Datasets/LWF_DATASET/lfw_train_pairs.txt'\n",
        "path_to_test_set ='./gdrive/MyDrive/Datasets/LWF_DATASET/lfw_test_pairs.txt'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpOAZ-uZB_lm"
      },
      "source": [
        "with open(path_to_train_set,\"r\") as f:\n",
        "  lines_train=f.readlines()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCt4YtBLCQUm"
      },
      "source": [
        "pos_train=[]\n",
        "neg_train=[]\n",
        "\n",
        "for line in lines_train:\n",
        "  x=line.split()\n",
        "  if x[2]==\"0\":\n",
        "    neg_train.append(x)\n",
        "  else:\n",
        "    pos_train.append(x)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL8kDJkPDamg"
      },
      "source": [
        "with open(path_to_test_set,\"r\") as f:\n",
        "  lines_test=f.readlines()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1sTHjzAEgvE"
      },
      "source": [
        "pos_test=[]\n",
        "neg_test=[]\n",
        "\n",
        "for line in lines_test:\n",
        "  x=line.split()\n",
        "  if x[2]==\"0\":\n",
        "    neg_test.append(x)\n",
        "  else:\n",
        "    pos_test.append(x)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTWIbDX5Euu6",
        "outputId": "9d90e1a3-302b-4483-cbeb-2727b24d30c7"
      },
      "source": [
        "print(\"Total no of train data: \",len(lines_train))\n",
        "print(\"Total no of test data : \",len(lines_test))\n",
        "\n",
        "print(\"Total no of positive data in training set: \",len(pos_train))\n",
        "print(\"Total no of negative data in training set: \",len(neg_train))\n",
        "\n",
        "print(\"Total no of positive data in testing set: \",len(pos_test))\n",
        "print(\"Total no of negative data in testing set: \",len(neg_test))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of train data:  2200\n",
            "Total no of test data :  1000\n",
            "Total no of positive data in training set:  1100\n",
            "Total no of negative data in training set:  1100\n",
            "Total no of positive data in testing set:  500\n",
            "Total no of negative data in testing set:  500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4kSNlg_E0Ud"
      },
      "source": [
        "import random\n",
        "\n",
        "# splitting positive train data\n",
        "total_pos_train=len(pos_train)\n",
        "total_pos_train_split=int(0.85*total_pos_train)\n",
        "total_pos_validation_split = total_pos_train-total_pos_train_split\n",
        "\n",
        "random.shuffle(pos_train)\n",
        "\n",
        "final_pos_train_data= [  pos_train[i]   for i in range(total_pos_train_split) ]\n",
        "final_pos_valid_data = [  pos_train[i]   for i in range(total_pos_train_split,total_pos_train)]\n",
        "\n",
        "assert len(final_pos_train_data)==total_pos_train_split, f\"Pos train data size mismatched. Found {len(final_pos_train_data)}, but expected {total_pos_train_split}\"\n",
        "assert len(final_pos_valid_data)==total_pos_validation_split, f\"Pos train data size mismatched. Found {len(final_pos_valid_data)}, but expected {total_pos_validation_split}\"\n",
        "\n",
        "\n",
        "# splitting negative train data\n",
        "total_neg_train=len(neg_train)\n",
        "total_neg_train_split=int(0.85*total_neg_train)\n",
        "total_neg_validation_split = total_neg_train-total_neg_train_split\n",
        "\n",
        "random.shuffle(neg_train)\n",
        "\n",
        "final_neg_train_data= [  neg_train[i]   for i in range(total_neg_train_split) ]\n",
        "final_neg_valid_data =[  neg_train[i]   for i in range(total_neg_train_split,total_neg_train)]\n",
        "\n",
        "assert len(final_neg_train_data)==total_neg_train_split, f\"Pos train data size mismatched. Found {len(final_neg_train_data)}, but expected {total_neg_train_split}\"\n",
        "assert len(final_neg_valid_data)==total_neg_validation_split, f\"Pos train data size mismatched. Found {len(final_neg_valid_data)}, but expected {total_neg_validation_split}\"\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR96iC_pOahD",
        "outputId": "6ad3b1fb-5b66-4039-9a9c-c8536eeddcf2"
      },
      "source": [
        "print(\"Total no of train data before split: \",len(lines_train))\n",
        "print(\"Total no of test data before split : \",len(lines_test))\n",
        "\n",
        "print(\"Total no of positive data in training set after split  : \",total_pos_train_split)\n",
        "print(\"Total no of positive data in validation set after split: \",total_pos_validation_split)\n",
        "\n",
        "print(\"Total no of negative data in training set after split  : \",total_neg_train_split)\n",
        "print(\"Total no of negative data in validation set after split: \",total_neg_validation_split)\n",
        "\n",
        "print(\"Total no of positive data in testing set: \",len(pos_test))\n",
        "print(\"Total no of negative data in testing set: \",len(neg_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of train data before split:  2200\n",
            "Total no of test data before split :  1000\n",
            "Total no of positive data in training set after split  :  935\n",
            "Total no of positive data in validation set after split:  165\n",
            "Total no of negative data in training set after split  :  935\n",
            "Total no of negative data in validation set after split:  165\n",
            "Total no of positive data in testing set:  500\n",
            "Total no of negative data in testing set:  500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chFKoRUZQgfo"
      },
      "source": [
        "Train_set_final=final_pos_train_data+final_neg_train_data\n",
        "random.shuffle(Train_set_final)\n",
        "\n",
        "Valid_set_final=final_pos_valid_data+final_neg_valid_data\n",
        "random.shuffle(Valid_set_final)\n",
        "\n",
        "Test_set_final =pos_test+neg_test\n",
        "random.shuffle(Test_set_final)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0yJ290TRgB9",
        "outputId": "c57554b6-4a6d-4d36-b286-9077772434ed"
      },
      "source": [
        "print(\"Train size: \",len(Train_set_final))\n",
        "print(\"Valid size: \",len(Valid_set_final))\n",
        "print(\"Test  size: \",len(Test_set_final))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size:  1870\n",
            "Valid size:  330\n",
            "Test  size:  1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPIZmchOTWcH"
      },
      "source": [
        "Train_set_final= [  \" \".join(lis) for lis in Train_set_final ]\n",
        "Valid_set_final= [  \" \".join(lis) for lis in Valid_set_final ]\n",
        "Test_set_final=  [  \" \".join(lis) for lis in Test_set_final ]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Y5Q-BMRulQ",
        "outputId": "daf4faa7-b6d5-4b21-95cc-956f19bb1c83"
      },
      "source": [
        "# checking for common elements\n",
        "def common_member(a, b):\n",
        "\ta_set = set(a)\n",
        "\tb_set = set(b)\n",
        "\n",
        "\tif (a_set & b_set):\n",
        "\t\tprint(a_set & b_set)\n",
        "\telse:\n",
        "\t\tprint(\"No common elements\")\n",
        "\t\n",
        "common_member(Train_set_final, Valid_set_final)\n",
        "common_member(Train_set_final, Test_set_final)\n",
        "common_member(Valid_set_final, Test_set_final)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No common elements\n",
            "No common elements\n",
            "No common elements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkP7IlybUOV1"
      },
      "source": [
        "To_write_in_file=[Train_set_final,Valid_set_final,Test_set_final]\n",
        "\n",
        "File_names =['./gdrive/MyDrive/Datasets/LWF_DATASET/Final_lfw_train_pairs.txt','./gdrive/MyDrive/Datasets/LWF_DATASET/Final_lfw_valid_pairs.txt','./gdrive/MyDrive/Datasets/LWF_DATASET/Final_lfw_test_pairs.txt']\n",
        "\n",
        "for ind,sets in enumerate(To_write_in_file):\n",
        "  with open(File_names[ind],\"w\") as f:\n",
        "    for element in sets:\n",
        "      f.write(element + \"\\n\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5JXsi62W_RX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}